{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b88cdbf0-68c8-46c4-8eae-a3c70e3a337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Easyouth Sew in Weft Hair Extensions Human Hai...   \n",
      "1  NICPOO No Heat Rollers Hair Curlers for Long H...   \n",
      "2  Cherry Vanilla Float GFHS 2020 Gentle Foaming ...   \n",
      "3  Anna Belen Girls\"Lila\" Large Grosgrain Bow Cli...   \n",
      "4  Snsowed 2 Pack Professional Curved Vented Styl...   \n",
      "\n",
      "                                         description features main_category  \n",
      "0                                                 []       []    All Beauty  \n",
      "1                                                 []       []    All Beauty  \n",
      "2  ['gentle foaming hand soap with cherry vanilla...       []    All Beauty  \n",
      "3                                                 []       []    All Beauty  \n",
      "4                                                 []       []    All Beauty  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"sampled_data.csv\")\n",
    "\n",
    "# Filter the DataFrame to include only the specified columns\n",
    "df = df[[\"title\", \"description\", \"features\", \"main_category\"]]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85529f63-86aa-437a-b78d-e8a3a530fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fed30cd-dba4-4e8c-8c59-30bc72f55251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            object\n",
       "description      object\n",
       "features         object\n",
       "main_category    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62887616-7dd6-4487-a900-1d1ec7e5d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'description' from object to string\n",
    "df['description'] = df['description'].astype('string')\n",
    "df['title'] = df['title'].astype('string')\n",
    "df['features'] = df['features'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e17c61d4-3dfd-43eb-934e-7a09609e69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the brackets and join the content inside the lists\n",
    "df['description'] = df['description'].str.strip(\"[]\").str.replace(\"'\", \"\")\n",
    "df['title'] = df['title'].str.strip(\"[]\").str.replace(\"'\", \"\")\n",
    "df['features'] = df['features'].str.strip(\"[]\").str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f7b5fda-66ba-47d3-841a-e58d5f7d3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     \n",
       "1                                                     \n",
       "2    gentle foaming hand soap with cherry vanilla s...\n",
       "3                                                     \n",
       "4                                                     \n",
       "Name: description, dtype: string"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b056d1f7-c885-49c4-ac16-817759ba83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the 'description' column is empty or contains only whitespace\n",
    "df = df[df['description'].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a6ff93b-0dd6-4581-9131-d3317dcdb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'title' is not empty\n",
    "df = df[(df['features'] != \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ab87b07-b529-40a8-8a3e-5546a8ae445e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2456"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "deff0052-2c8c-4eee-b386-c5ca24153c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/prers/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/prers/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/prers/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/prers/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "# NLTK downloads:\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "def clean_text_column_with_lemmatization(df, column_name):\n",
    "    \"\"\"\n",
    "    Cleans text data in a specified column of a DataFrame, including lemmatization with POS tagging.\n",
    "    \n",
    "    Steps:\n",
    "    - Convert to lowercase\n",
    "    - Remove URLs\n",
    "    - Remove HTML tags\n",
    "    - Remove punctuation\n",
    "    - Remove numbers\n",
    "    - Remove stopwords\n",
    "    - Tokenize text\n",
    "    - Perform POS tagging and lemmatize tokens\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The DataFrame containing the text column.\n",
    "    - column_name (str): The name of the column to clean.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with cleaned text column.\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(text):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r\"<.*?>\", \"\", text)\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        # Remove numbers\n",
    "        text = re.sub(r\"\\d+\", \"\", text)\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # POS tagging\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        # Debug: Print POS tags for verification\n",
    "        #print(f\"Original text: {text}\")\n",
    "        #print(f\"POS Tags: {pos_tags}\")\n",
    "        # Lemmatize tokens with POS tagging\n",
    "        tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "        # Debug: Print lemmatized tokens\n",
    "        #print(f\"Lemmatized tokens: {tokens}\")\n",
    "        # Join tokens back into a string\n",
    "        text = \" \".join(tokens)\n",
    "        return text\n",
    "    \n",
    "    # Apply cleaning to the specified column\n",
    "    df[column_name] = df[column_name].astype(str).apply(clean_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64efb588-6d35-447b-8db3-63a980e2874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     The Perfect Woman Toning & Firming Complex is ...\n",
       "11    Large butterfly clamps which is perfect for se...\n",
       "18    The new ultimate29 premium professional are to...\n",
       "23    Grand Parfums Perfume Oils, Body and Incense o...\n",
       "29    \"Design Essentials Natural coconut & Monoid de...\n",
       "Name: description, dtype: string"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9f61f99-513a-4ed9-b287-239781970fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     100% Natural advanced enzyme technology, Lift ...\n",
       "11    Perfect for separating long or short hair, 12 ...\n",
       "18    This professional line offers a great mixture ...\n",
       "23    FIRST QUALITY SCENT & AROMA - PHTHALATE FREE: ...\n",
       "29    Provides maximum hydration for all day moistur...\n",
       "Name: features, dtype: string"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['features'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df4ad640-d354-4159-9266-ab5d30a39548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty values in 'title': 0\n",
      "Number of empty values in 'features': 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: Count empty values in 'title' and 'features' columns\n",
    "empty_title_count = df['title'].isna().sum()\n",
    "empty_features_count = df['features'].isna().sum()\n",
    "\n",
    "print(f\"Number of empty values in 'title': {empty_title_count}\")\n",
    "print(f\"Number of empty values in 'features': {empty_features_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49c67aa5-771e-49dd-a860-5b2f5ca21bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the columns\n",
    "df['content'] = df['title'] + \" | \" + df['features'] + \" | \" + df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfd164ee-94ef-4ed2-bf62-ca2ff7a496e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'text' column\n",
    "df = clean_text_column_with_lemmatization(df, 'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "426dad21-230d-4f3e-b920-15427aa5c51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     bottle perfect woman tone firm complex recomme...\n",
       "11    softn style large butterfly clamp count perfec...\n",
       "18    x u dove grey bleach safe salon towel pack pro...\n",
       "23    grand parfums premium burn fragrance oil egypt...\n",
       "29    design essential natural coconut monoi deep mo...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f08207d1-11c4-4010-861a-4a383df5e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
